{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luanaxcardoso/Squad04-Semantic-Segmentation-Drone-Dataset/blob/main/Sq04_atividade01_062025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de Segmenta√ß√£o de Imagens Urbanas\n",
        "## Bootcamp Machine Learning - Atl√¢ntico Avanti: 06/2025.\n",
        "\n",
        "Neste primeira etapa, o trabalho avaliou o dataset \"Semantic Segmentation Drone Dataset\" e teve como foco principal a an√°lise explorat√≥ria dos dados dispon√≠veis.\n",
        "\n",
        "**Objetivo**: apresentar informa√ß√µes iniciais sobre as caracter√≠sticas do dataset.\n",
        "\n",
        "**Integrantes**:\n",
        "\n",
        "- Felipe Ferreira Dos Santos\n",
        "- Luana Aparecida Cardoso\n",
        "- Hozana Izadora Da Silva Ferreira\n",
        "- Patrick Wohrle Guimaraes\n",
        "- Sarah Cavalcante Salvino\n",
        "\n",
        "**Dataset dispon√≠vel em**: [Kaggle]( https://www.kaggle.com/datasets/santurini/semantic-segmentation-drone-dataset?select=Image)"
      ],
      "metadata": {
        "id": "4KDKkJhuqPDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìö Instala√ß√µes, montar drive (Gdrive), importar Bibliotecas e  leitura dataset"
      ],
      "metadata": {
        "id": "f-KEQy0wq0J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instala√ß√£o de bibliotecas necess√°rias\n",
        "!pip install pandas numpy matplotlib Pillow opencv-python imagehash tqdm tabulate"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Wovo0oJmsJl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Montar o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-drNDexiq4FS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import imagehash\n",
        "import ast\n",
        "import json\n",
        "from tqdm.notebook import tqdm # Usar tqdm.notebook para barras de progresso no Colab\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from tabulate import tabulate\n",
        "from pathlib import Path\n",
        "from itertools import combinations\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# Defini√ß√£o dos caminhos para o dataset no Google Drive\n",
        "# AJUSTE ESTES CAMINHOS para onde voc√™ salvou o dataset no SEU Google Drive\n",
        "# Exemplo: se voc√™ salvou o conte√∫do da pasta 'semantic-segmentation-drone-dataset'\n",
        "# dentro de 'Meu Drive/datasets/semantic-segmentation-drone-dataset'\n",
        "BASE_DIR = \"/content/drive/MyDrive/dataset\"\n",
        "IMAGE_DIR = os.path.join(BASE_DIR, \"binary_dataset/binary_dataset/original_images/\")\n",
        "MASK_DIR = os.path.join(BASE_DIR, \"binary_dataset/binary_dataset/images_semantic/\")\n",
        "\n",
        "# Verificar se os diret√≥rios existem\n",
        "if not os.path.exists(IMAGE_DIR):\n",
        "    print(f\"ERRO: Diret√≥rio de imagens n√£o encontrado em {IMAGE_DIR}\")\n",
        "    print(\"Por favor, ajuste o caminho IMAGE_DIR para o local correto no seu Google Drive.\")\n",
        "if not os.path.exists(MASK_DIR):\n",
        "    print(f\"ERRO: Diret√≥rio de m√°scaras n√£o encontrado em {MASK_DIR}\")\n",
        "    print(\"Por favor, ajuste o caminho MASK_DIR para o local correto no seu Google Drive.\")\n",
        "\n",
        "# Lista de arquivos nos diret√≥rios\n",
        "# Use um bloco try-except caso os diret√≥rios n√£o existam (devido a caminhos incorretos)\n",
        "try:\n",
        "    image_files = sorted([f for f in os.listdir(IMAGE_DIR) if os.path.isfile(os.path.join(IMAGE_DIR, f))])\n",
        "    mask_files = sorted([f for f in os.listdir(MASK_DIR) if os.path.isfile(os.path.join(MASK_DIR, f))])\n",
        "\n",
        "    print(f\"Total de imagens encontradas: {len(image_files)}\")\n",
        "    print(f\"Total de m√°scaras encontradas: {len(mask_files)}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"\\nN√£o foi poss√≠vel listar os arquivos. Verifique se os caminhos IMAGE_DIR e MASK_DIR est√£o corretos.\")\n",
        "    image_files = [] # Definir como lista vazia para evitar erros nos pr√≥ximos passos\n",
        "    mask_files = []"
      ],
      "metadata": {
        "id": "m2G7hl3Br-sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integridade dos Arquivos"
      ],
      "metadata": {
        "id": "x5r__Wd0zEkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "\n",
        "# Montar o Google Drive (execute esta c√©lula no Colab antes de rodar o resto)\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# Defina os caminhos com base no seu Google Drive\n",
        "#BASE_DIR = \"/content/drive/MyDrive/dataset\" # This is correct, points to MyDrive/dataset\n",
        "\n",
        "# Corre√ß√£o aqui: remova o \"dataset/\" extra\n",
        "#IMAGE_DIR = os.path.join(BASE_DIR, \"original_images/\")\n",
        "#MASK_DIR = os.path.join(BASE_DIR, \"images_semantic/\")\n",
        "#IMAGE_DIR = os.path.join(BASE_DIR, \"binary_dataset/binary_dataset/original_images/\")\n",
        "#MASK_DIR = os.path.join(BASE_DIR, \"binary_dataset/binary_dataset/images_semantic/\")\n",
        "\n",
        "# Esta fun√ß√£o verifica:\n",
        "# 1. Se os arquivos das duas pastas t√™m o mesmo formato (ex: .png)\n",
        "# 2. Se os arquivos t√™m os mesmos nomes (ignorando a extens√£o)\n",
        "def verificar_imagens(original_dir, semantic_dir):\n",
        "    resultados = []\n",
        "\n",
        "    def obter_info_diretorio(pasta):\n",
        "        # Listar apenas arquivos, ignorando subdiret√≥rios\n",
        "        arquivos = [f for f in os.listdir(pasta) if os.path.isfile(os.path.join(pasta, f))]\n",
        "        extensoes = {os.path.splitext(f)[-1].lower() for f in arquivos}\n",
        "        nomes_base = {os.path.splitext(f)[0] for f in arquivos}\n",
        "        return arquivos, extensoes, nomes_base\n",
        "\n",
        "    try:\n",
        "        arquivos_ori, ext_ori, nomes_ori = obter_info_diretorio(original_dir)\n",
        "        arquivos_sem, ext_sem, nomes_sem = obter_info_diretorio(semantic_dir)\n",
        "    except FileNotFoundError as e:\n",
        "        return [f\"‚ùå Erro ao acessar as pastas: {e}\"]\n",
        "    except Exception as e: # Catch other potential errors during listing\n",
        "        return [f\"‚ùå Ocorreu um erro inesperado ao processar os diret√≥rios: {e}\"]\n",
        "\n",
        "\n",
        "    if len(ext_ori) == 1:\n",
        "        resultados.append(f\"‚úÖ original_images: todas as imagens est√£o no formato {list(ext_ori)[0]}\")\n",
        "    else:\n",
        "        resultados.append(\"‚ö†Ô∏è original_images cont√©m m√∫ltiplos formatos:\")\n",
        "        resultados.extend([f\"   - {ext}\" for ext in sorted(ext_ori)])\n",
        "\n",
        "    if len(ext_sem) == 1:\n",
        "        resultados.append(f\"‚úÖ images_semantic: todas as imagens est√£o no formato {list(ext_sem)[0]}\")\n",
        "    else:\n",
        "        resultados.append(\"‚ö†Ô∏è images_semantic cont√©m m√∫ltiplos formatos:\")\n",
        "        resultados.extend([f\"   - {ext}\" for ext in sorted(ext_sem)])\n",
        "\n",
        "    if nomes_ori == nomes_sem:\n",
        "        resultados.append(\"‚úÖ As duas pastas possuem os mesmos nomes de arquivos (sem extens√£o).\")\n",
        "    else:\n",
        "        # Sort these sets to ensure consistent output order\n",
        "        faltando_em_sem = sorted(nomes_ori - nomes_sem)\n",
        "        faltando_em_ori = sorted(nomes_sem - nomes_ori)\n",
        "\n",
        "        resultados.append(\"‚ö†Ô∏è Diferen√ßas entre os nomes de arquivos encontrados:\")\n",
        "        if faltando_em_sem:\n",
        "            resultados.append(\"   - Presentes em original_images, mas faltando em images_semantic:\")\n",
        "            resultados.extend([f\"     - {nome}\" for nome in faltando_em_sem])\n",
        "        if faltando_em_ori:\n",
        "            resultados.append(\"   - Presentes em images_semantic, mas faltando em original_images:\")\n",
        "            resultados.extend([f\"     - {nome}\" for nome in faltando_em_ori])\n",
        "\n",
        "    return resultados\n",
        "\n",
        "# Executa a verifica√ß√£o e imprime os resultados\n",
        "print(\"\\nüìã Resultados da verifica√ß√£o:\\n\")\n",
        "for linha in verificar_imagens(IMAGE_DIR, MASK_DIR):\n",
        "    print(linha)"
      ],
      "metadata": {
        "id": "OO-bkJmVjbRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Consist√™ncia dos Metadados**"
      ],
      "metadata": {
        "id": "6MRexX54Kijh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Verifique se h√° valores ausentes nos metadados e como esses casos s√£o tratados.**\n",
        "\n",
        "* **Verifique valores inconsistentes, por exemplo: dimens√µes de imagens fora do esperado**\n"
      ],
      "metadata": {
        "id": "K7WOxCInKwsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CSV_PATH = r\"/content/metadata_binario.csv\"\n",
        "VALORES_INVALIDOS = {\"\", \"N/A\", \"None\", \"[]\", \"{}\", \"nan\", \"NaN\", \"n/a\", \"null\"}\n",
        "\n",
        "CLASSES_BINARIAS = {\n",
        "    0: {0, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20},  # background\n",
        "    1: {1, 2, 3, 4, 9}  # objeto\n",
        "}\n",
        "\n",
        "# Fun√ß√£o para formatar porcentagens de acordo com as faixas de pixels\n",
        "# de background e objeto\n",
        "def formatar_porcentagem(valor):\n",
        "    if valor == 0:\n",
        "        return \"0%\"\n",
        "    elif valor < 0.01:\n",
        "        return \"<1%\"\n",
        "    elif valor < 0.1:\n",
        "        return \"1-10%\"\n",
        "    elif valor < 0.25:\n",
        "        return \"10-25%\"\n",
        "    elif valor < 0.5:\n",
        "        return \"25-50%\"\n",
        "    elif valor < 0.75:\n",
        "        return \"50-75%\"\n",
        "    else:\n",
        "        return \">75%\"\n",
        "\n",
        "def verificar_metadados(csv_path):\n",
        "    if not os.path.exists(csv_path):\n",
        "        print(f\"[ERRO] Arquivo n√£o encontrado: {csv_path}\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    total_imagens = len(df)\n",
        "    print(f\"\\n‚ÑπÔ∏è Total de imagens no dataset: {total_imagens:,}\")\n",
        "\n",
        "    print(\"\\n 1. Valores ausentes ou inv√°lidos:\")\n",
        "    print(\"-\" * 50)\n",
        "    nulos = df.isnull().sum()\n",
        "    nulos = nulos[nulos > 0]\n",
        "\n",
        "    if nulos.empty:\n",
        "        print(\" Nenhum valor ausente (NaN) encontrado.\")\n",
        "    else:\n",
        "        print(\" Valores ausentes encontrados:\")\n",
        "        print(tabulate(nulos.reset_index().rename(columns={\"index\": \"Coluna\", 0: \"Total NaN\"}), headers=\"keys\", tablefmt=\"pretty\"))\n",
        "\n",
        "    simbolicos_invalidos = []\n",
        "    for col in df.columns:\n",
        "        count = df[col].astype(str).isin(VALORES_INVALIDOS).sum()\n",
        "        if count > 0:\n",
        "            simbolicos_invalidos.append((col, count))\n",
        "\n",
        "    if not simbolicos_invalidos:\n",
        "        print(\" Nenhum valor simb√≥lico inv√°lido encontrado.\")\n",
        "    else:\n",
        "        print(\"\\n Valores simb√≥licos inv√°lidos encontrados:\")\n",
        "        print(tabulate(simbolicos_invalidos, headers=[\"Coluna\", \"Quantidade\"], tablefmt=\"pretty\"))\n",
        "\n",
        "    print(\"\\n 2. Dimens√µes das imagens:\")\n",
        "    print(\"-\" * 50)\n",
        "    retangulares = df[df[\"largura\"] != df[\"altura\"]]\n",
        "    if retangulares.empty:\n",
        "        print(\" Todas as imagens s√£o quadradas (largura = altura).\")\n",
        "    else:\n",
        "        primeiro = retangulares.iloc[0]\n",
        "        print(f\"  {len(retangulares)} imagens retangulares encontradas.\")\n",
        "        print(f\"  Exemplo: arquivo={primeiro['arquivo']}, largura={primeiro['largura']}, altura={primeiro['altura']}\")\n",
        "\n",
        "\n",
        "    print(\"\\n 3. Consist√™ncia dos dados de pixels:\")\n",
        "    print(\"-\" * 50)\n",
        "    df[\"soma_pixels\"] = df[\"pixels_background\"] + df[\"pixels_objeto\"]\n",
        "    inconsistencias = df[df[\"soma_pixels\"] != df[\"total_pixels\"]]\n",
        "\n",
        "    if inconsistencias.empty:\n",
        "        print(\" Todas as imagens t√™m soma de pixels (background + objeto) igual ao total.\")\n",
        "    else:\n",
        "        print(f\" {len(inconsistencias)} imagens com soma de pixels inconsistente:\")\n",
        "        print(tabulate(inconsistencias[[\"arquivo\", \"pixels_background\", \"pixels_objeto\", \"total_pixels\"]].head(), headers=\"keys\", tablefmt=\"pretty\"))\n",
        "\n",
        "    df[\"soma_proporcao\"] = df[\"proporcao_background\"] + df[\"proporcao_objeto\"]\n",
        "    proporcoes_inconsistentes = df[abs(df[\"soma_proporcao\"] - 1.0) > 0.01]\n",
        "    if proporcoes_inconsistentes.empty:\n",
        "        print(\" Todas as imagens t√™m propor√ß√µes que somam aproximadamente 1.0.\")\n",
        "    else:\n",
        "        print(f\" {len(proporcoes_inconsistentes)} imagens com propor√ß√µes inconsistentes:\")\n",
        "        print(tabulate(proporcoes_inconsistentes[[\"arquivo\", \"proporcao_background\", \"proporcao_objeto\", \"soma_proporcao\"]].head(), headers=\"keys\", tablefmt=\"pretty\"))\n",
        "\n",
        "    print(\"\\n 4. Verifica√ß√£o das faixas de porcentagem:\")\n",
        "    print(\"-\" * 50)\n",
        "    df[\"faixa_calculada\"] = df[\"proporcao_objeto\"].apply(formatar_porcentagem)\n",
        "    faixas_incorretas = df[df[\"faixa_proporcao_objeto\"] != df[\"faixa_calculada\"]]\n",
        "    if faixas_incorretas.empty:\n",
        "        print(\" Todas as faixas de porcentagem est√£o corretamente calculadas.\")\n",
        "    else:\n",
        "        print(f\" {len(faixas_incorretas)} imagens com faixas de porcentagem incorretas:\")\n",
        "        print(tabulate(faixas_incorretas[[\"arquivo\", \"proporcao_objeto\", \"faixa_proporcao_objeto\", \"faixa_calculada\"]].head(), headers=\"keys\", tablefmt=\"pretty\"))\n",
        "\n",
        "        # 5. An√°lise bin√°ria: presen√ßa de fundo e objeto\n",
        "    print(\"\\n 5. An√°lise bin√°ria (com base em background e objeto):\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    if {\"somente_background\", \"somente_objeto\", \"background_e_objeto\"}.issubset(df.columns):\n",
        "        total = len(df)\n",
        "        apenas_bg = df[\"somente_background\"].sum()\n",
        "        apenas_obj = df[\"somente_objeto\"].sum()\n",
        "        ambos = df[\"background_e_objeto\"].sum()\n",
        "\n",
        "        print(f\" Imagens com apenas background: {apenas_bg} ({apenas_bg / total:.1%})\")\n",
        "        print(f\" Imagens com apenas objeto: {apenas_obj} ({apenas_obj / total:.1%})\")\n",
        "        print(f\" Imagens com background e objeto: {ambos} ({ambos / total:.1%})\")\n",
        "\n",
        "        if apenas_bg > 0:\n",
        "            print(\"  Algumas imagens n√£o t√™m nenhum pixel de objeto ‚Äî podem ser irrelevantes para o modelo.\")\n",
        "        if apenas_obj > 0:\n",
        "            print(\"  Algumas imagens t√™m apenas objeto ‚Äî verifique se o fundo foi corretamente identificado como classe 0.\")\n",
        "    else:\n",
        "        print(\" As colunas 'somente_background', 'somente_objeto', 'background_e_objeto' n√£o est√£o presentes no CSV.\")\n",
        "        print(\"Sem elas, n√£o √© poss√≠vel avaliar a presen√ßa dos grupos bin√°rios nas m√°scaras.\")\n",
        "\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\" RESUMO FINAL DA QUALIDADE DOS METADADOS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    problemas = []\n",
        "    if not nulos.empty:\n",
        "        problemas.append(f\"‚Ä¢ Valores ausentes (NaN) em {len(nulos)} coluna(s)\")\n",
        "    if simbolicos_invalidos:\n",
        "        problemas.append(f\"‚Ä¢ Valores simb√≥licos inv√°lidos em {len(simbolicos_invalidos)} coluna(s)\")\n",
        "    if not retangulares.empty:\n",
        "        problemas.append(f\"‚Ä¢ {len(retangulares)} imagens retangulares (largura ‚â† altura)\")\n",
        "    if not inconsistencias.empty:\n",
        "        problemas.append(f\"‚Ä¢ {len(inconsistencias)} imagens com soma de pixels inconsistente\")\n",
        "    if not proporcoes_inconsistentes.empty:\n",
        "        problemas.append(f\"‚Ä¢ {len(proporcoes_inconsistentes)} imagens com propor√ß√µes inconsistentes\")\n",
        "    if not faixas_incorretas.empty:\n",
        "        problemas.append(f\"‚Ä¢ {len(faixas_incorretas)} imagens com faixas de porcentagem incorretas\")\n",
        "    if 'classes_presentes' in df.columns and classes_nao_mapeadas:\n",
        "        problemas.append(f\"‚Ä¢ {len(classes_nao_mapeadas)} classe(s) n√£o mapeadas no agrupamento bin√°rio\")\n",
        "\n",
        "    if problemas:\n",
        "        print(\"\\n PROBLEMAS ENCONTRADOS:\")\n",
        "        for problema in problemas:\n",
        "            print(problema)\n",
        "    else:\n",
        "        print(\"\\n METADADOS CONSISTENTES: Nenhum problema grave encontrado!\")\n",
        "        print(\"O dataset parece estar bem preparado para uso em modelos de segmenta√ß√£o sem√¢ntica.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    verificar_metadados(CSV_PATH)\n",
        "\n"
      ],
      "metadata": {
        "id": "-sn7aFfdK__Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embora os metadados estejam √≠ntegros e sem valores ausentes, sem erros de soma de pixels ou de propor√ß√µes e com todas as faixas corretamente calculadas, h√° um ponto cr√≠tico: todas as 400 imagens s√£o retangulares (960 √ó 736 no exemplo).\n",
        "\n",
        "E idealmente dever√≠amos trabalhar com formatos quadrados para manter a propor√ß√£o dos pixels em tarefas de segmenta√ß√£o sem√¢ntica.\n",
        "\n",
        "Esse desvio pode afetar a performance de modelos que esperam entradas quadradas, portanto, uma solu√ß√£o seria redimensionar ou recortar as m√°scaras para um formato uniforme."
      ],
      "metadata": {
        "id": "wGnsfJkTo98K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Ud6TyNiGMFBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Qualidade das Imagens (Identificar Imagens Corrompidas)\n",
        "- Objetivo: Identificar imagens (e m√°scaras) que n√£o podem ser abertas ou processadas, indicando corrup√ß√£o."
      ],
      "metadata": {
        "id": "39FLL3Sj_SM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_corrupted_files(directory, filenames, file_type):\n",
        "    \"\"\"\n",
        "    Verifica se os arquivos em um diret√≥rio espec√≠fico est√£o corrompidos\n",
        "    tentando abri-los e verificando sua integridade usando Pillow.\n",
        "\n",
        "    Args:\n",
        "        directory (str): O caminho para o diret√≥rio contendo os arquivos.\n",
        "        filenames (list): Uma lista de nomes de arquivos a serem verificados.\n",
        "        file_type (str): Um nome descritivo para o tipo de arquivo (ex: 'imagens', 'm√°scaras').\n",
        "\n",
        "    Returns:\n",
        "        list: Uma lista de tuplas, onde cada tupla cont√©m o nome do arquivo\n",
        "              corrompido e a mensagem de erro capturada.\n",
        "    \"\"\"\n",
        "    corrupted_list = []\n",
        "    print(f\"\\nVerificando {file_type} corrompidas...\")\n",
        "\n",
        "    # Usa tqdm para mostrar uma barra de progresso durante a itera√ß√£o\n",
        "    for filename in tqdm(filenames, desc=f\"Verificando {file_type}\"):\n",
        "        filepath = os.path.join(directory, filename)\n",
        "        try:\n",
        "            # Usa 'with' para garantir que o arquivo seja fechado automaticamente\n",
        "            # Image.open() abre o arquivo\n",
        "            with Image.open(filepath) as img:\n",
        "                # img.verify() verifica o cabe√ßalho e a estrutura do arquivo\n",
        "                # sem carregar todos os dados de pixel. Levanta um erro se corrompido.\n",
        "                img.verify()\n",
        "            # Nota: Capturar 'Exception' pega qualquer erro durante open/verify.\n",
        "            # Em casos mais espec√≠ficos, pode-se capturar erros como IOError,\n",
        "            # PIL.UnidentifiedImageError, etc., para tratamento mais granular.\n",
        "        except Exception as e:\n",
        "            # Se ocorrer um erro, o arquivo √© considerado corrompido\n",
        "            corrupted_list.append((filename, str(e)))\n",
        "\n",
        "    return corrupted_list\n",
        "\n",
        "# --- In√≠cio do Algoritmo Principal ---\n",
        "\n",
        "# Verificar se os diret√≥rios foram encontrados e cont√™m arquivos antes de prosseguir\n",
        "# Assume que 'image_files' e 'mask_files' s√£o listas de nomes de arquivos\n",
        "# e 'IMAGE_DIR' e 'MASK_DIR' s√£o os caminhos para os diret√≥rios.\n",
        "# Estas vari√°veis devem ser definidas ANTES deste bloco de c√≥digo.\n",
        "if 'image_files' in locals() and 'mask_files' in locals() and image_files and mask_files:\n",
        "\n",
        "    # Chama a fun√ß√£o para verificar imagens\n",
        "    corrupted_images = check_corrupted_files(IMAGE_DIR, image_files, 'imagens')\n",
        "\n",
        "    # Chama a fun√ß√£o para verificar m√°scaras\n",
        "    corrupted_masks = check_corrupted_files(MASK_DIR, mask_files, 'm√°scaras')\n",
        "\n",
        "    # --- Relat√≥rio dos Resultados ---\n",
        "    if not corrupted_images:\n",
        "        print(\"Verifica√ß√£o de Qualidade: Nenhuma imagem corrompida encontrada.\")\n",
        "    else:\n",
        "        print(f\"Verifica√ß√£o de Qualidade: {len(corrupted_images)} imagens corrompidas encontradas.\")\n",
        "        # Descomente as linhas abaixo para ver exemplos dos arquivos corrompidos\n",
        "        # print(\" Exemplos (arquivo, erro):\")\n",
        "        # for item in corrupted_images[:10]:\n",
        "        #     print(f\"  {item[0]}: {item[1]}\")\n",
        "\n",
        "    if not corrupted_masks:\n",
        "        print(\"Verifica√ß√£o de Qualidade: Nenhuma m√°scara corrompida encontrada.\")\n",
        "    else:\n",
        "        print(f\"Verifica√ß√£o de Qualidade: {len(corrupted_masks)} m√°scaras corrompidas encontradas.\")\n",
        "        # Descomente as linhas abaixo para ver exemplos dos arquivos corrompidos\n",
        "        # print(\" Exemplos (arquivo, erro):\")\n",
        "        # for item in corrupted_masks[:10]:\n",
        "        #     print(f\"  {item[0]}: {item[1]}\")\n",
        "\n",
        "else:\n",
        "    # Este bloco √© executado se as listas de arquivos estiverem vazias ou n√£o definidas\n",
        "    print(\"\\nPulando Verifica√ß√£o de Qualidade: Listas de arquivos de imagem/m√°scara vazias ou n√£o definidas.\")\n",
        "    print(\"Por favor, verifique se IMAGE_DIR e MASK_DIR est√£o definidos corretamente\")\n",
        "    print(\"e se cont√™m arquivos antes de executar esta se√ß√£o.\")"
      ],
      "metadata": {
        "id": "-5rH2XI8_h7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MUz-9K3JUYh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Duplicatas\n",
        "\n",
        "‚ñ† Identifique imagens duplicadas que possam enviesar os resultados.  \n",
        "‚ñ† Verifique duplicatas no arquivo de informa√ß√µes.\n",
        "\n"
      ],
      "metadata": {
        "id": "jej31UzkSZiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminho da pasta\n",
        "caminho_pasta = Path(\"binary_dataset/binary_dataset/images_semantic/\")\n",
        "\n",
        "# Tamanho fixo para padronizar\n",
        "tamanho_padrao = (256, 256)\n",
        "\n",
        "# Carrega todas as imagens .png\n",
        "imagens = list(caminho_pasta.glob(\"*.png\"))\n",
        "imagens_dict = {}\n",
        "\n",
        "# Carrega e padroniza\n",
        "for caminho in imagens:\n",
        "    img = cv2.imread(str(caminho), cv2.IMREAD_GRAYSCALE)\n",
        "    if img is not None:\n",
        "        img_padronizada = cv2.resize(img, tamanho_padrao)\n",
        "        imagens_dict[caminho.name] = img_padronizada\n",
        "\n",
        "# Comparar pixel a pixel\n",
        "print(\" Verificando imagens exatamente iguais:\\n\")\n",
        "iguais = False\n",
        "for (nome1, img1), (nome2, img2) in combinations(imagens_dict.items(), 2):\n",
        "    if np.array_equal(img1, img2):\n",
        "        print(f\"üü• Iguais: {nome1} == {nome2}\")\n",
        "        iguais = True\n",
        "\n",
        "if not iguais:\n",
        "    print(\"‚úÖ Nenhuma imagem exatamente igual encontrada.\")"
      ],
      "metadata": {
        "id": "hFSTgZoIUE4g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}